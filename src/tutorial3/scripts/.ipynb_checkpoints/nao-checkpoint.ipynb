{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 2)\n",
      "(23, 2)\n",
      "(92, 2)\n",
      "(23, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_size = 2\n",
    "output_size = 2\n",
    "data_path = \"\"\n",
    "Data = np.loadtxt(\"data.txt\",delimiter=\",\")\n",
    "#test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
    "                      # delimiter=\",\") \n",
    "X_data = Data[:,1:3]\n",
    "Y_data = Data[:,3:]\n",
    "N = X_data.shape[0]\n",
    "val_portion = 0.2;\n",
    "X_train = X_data[:int((1-val_portion)*N),:]\n",
    "X_test = X_data[int((1-val_portion)*N):,:]\n",
    "Y_train = Y_data[:int((1-val_portion)*N),:]\n",
    "Y_test = Y_data[int((1-val_portion)*N):,:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97361614 0.30870003]\n",
      " [0.83661896 0.79963921]\n",
      " [0.87152534 0.88154571]\n",
      " [0.76958824 0.86492347]\n",
      " [0.55046254 0.47811772]\n",
      " [0.86853924 0.38849011]\n",
      " [0.22924485 0.3086998 ]\n",
      " [0.71370061 0.36552551]\n",
      " [0.86554711 0.32416997]\n",
      " [0.78593166 0.36441031]\n",
      " [0.37005354 0.88775759]\n",
      " [0.11475011 0.30870004]\n",
      " [0.20793329 0.34847329]\n",
      " [0.88327264 0.76103331]\n",
      " [0.98410492 0.30870001]\n",
      " [0.8978845  0.75354927]\n",
      " [0.08456717 0.30870001]\n",
      " [0.82553008 0.37821657]\n",
      " [0.10212943 0.30869996]\n",
      " [0.07890575 0.32286834]\n",
      " [0.6097064  0.52936493]\n",
      " [0.7731768  0.63343387]\n",
      " [0.87670613 0.74711471]]\n"
     ]
    }
   ],
   "source": [
    "fac_x = 0.99 / 320\n",
    "fac_y = 0.99 / 240\n",
    "train_X = np.zeros((X_train.shape))\n",
    "train_Y = np.zeros(Y_train.shape)\n",
    "test_X = np.zeros((X_test.shape))\n",
    "test_Y = np.zeros(Y_test.shape)\n",
    "\n",
    "train_X[:,0] = np.asfarray(X_train[:, 0]) * fac_x + 0.01 - 0.5\n",
    "train_X[:,1] = np.asfarray(X_train[:, 1]) * fac_y + 0.01 -0.5\n",
    "test_X[:,0] = np.asfarray(X_test[:, 0]) * fac_x + 0.01 -0.5\n",
    "test_X[:,1] = np.asfarray(X_test[:, 1]) * fac_y + 0.01 -0.5\n",
    "\n",
    "train_Y[:,0] = (np.asfarray(Y_train[:,0]) - (-0.7))/0.7\n",
    "train_Y[:,1] = (np.asfarray(Y_train[:,1]) - (-0.3))/1\n",
    "test_Y[:,0] = (np.asfarray(Y_test[:,0]) - (-0.7))/0.7\n",
    "test_Y[:,1] = (np.asfarray(Y_test[:,1]) - (-0.3))/1\n",
    "\n",
    "print test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = np.arange(10)\\n\\nfor label in range(10):\\n    one_hot = (lr==label).astype(np.int)\\n    print(\"label: \", label, \" in one-hot representation: \", one_hot)\\n    lr = np.arange(no_of_different_labels)\\n\\n# transform labels into one hot representation\\ntrain_labels_one_hot = (lr==train_labels).astype(np.float)\\ntest_labels_one_hot = (lr==test_labels).astype(np.float)\\n\\n# we don\\'t want zeroes and ones in the labels neither:\\ntrain_labels_one_hot[train_labels_one_hot==0] = 0.01\\ntrain_labels_one_hot[train_labels_one_hot==1] = 0.99\\ntest_labels_one_hot[test_labels_one_hot==0] = 0.01\\ntest_labels_one_hot[test_labels_one_hot==1] = 0.99\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lr = np.arange(10)\n",
    "\n",
    "for label in range(10):\n",
    "    one_hot = (lr==label).astype(np.int)\n",
    "    print(\"label: \", label, \" in one-hot representation: \", one_hot)\n",
    "    lr = np.arange(no_of_different_labels)\n",
    "\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-53e395b7264f>, line 141)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-53e395b7264f>\"\u001b[0;36m, line \u001b[0;32m141\u001b[0m\n\u001b[0;31m    input_vector = np.concatenate( (input_vector; np.ones((input_vector.shape[0],1))) )\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "activation_function = sigmoid\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd,\n",
    "                     (upp - mean) / sd, \n",
    "                     loc=mean, \n",
    "                     scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "        \n",
    "    \n",
    "    def __init__(self, \n",
    "                 network_structure, # ie. [input_nodes, hidden1_nodes, ... , hidden_n_nodes, output_nodes]\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "\n",
    "        self.structure = network_structure\n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "\n",
    "    \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []    \n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        while layer_index < no_of_layers:\n",
    "            nodes_in = self.structure[layer_index-1]\n",
    "            nodes_out = self.structure[layer_index]\n",
    "            n = (nodes_in + bias_node) * nodes_out\n",
    "            # initialize the weight matrix of each layer\n",
    "            rad = 1 / np.sqrt(nodes_in)\n",
    "            X = truncated_normal(mean=2, sd=1, low=-rad, upp=rad)\n",
    "            wm = X.rvs(n).reshape((nodes_out, nodes_in + bias_node))\n",
    "            #attach to the parameter\n",
    "            self.weights_matrices.append(wm)\n",
    "            layer_index += 1\n",
    "\n",
    "        \n",
    "        \n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        # input_vector and target_vector can be tuple, list or ndarray\n",
    "                                       \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        \n",
    "        # forward pass\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the various layers:\n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1:\n",
    "            #take the last element of res_vector\n",
    "            in_vector = res_vectors[-1]\n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             [[self.bias]]) )\n",
    "                res_vectors[-1] = in_vector\n",
    "            x = np.dot(self.weights_matrices[layer_index], in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "            \n",
    "        #out_vector = np.tanh(x)\n",
    "        \n",
    "        \n",
    "        # backward pass\n",
    "        layer_index = no_of_layers - 1\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        # The input vectors to the various layers\n",
    "        # output_errors = target_vector - out_vector\n",
    "        output_errors= 2*(target_vector-out_vector)\n",
    "        #tmp = 1 - out_vector*out_vector\n",
    "        while layer_index > 0:\n",
    "            out_vector = res_vectors[layer_index]\n",
    "            in_vector = res_vectors[layer_index-1]\n",
    "\n",
    "            if self.bias and not layer_index==(no_of_layers-1):\n",
    "                out_vector = out_vector[:-1,:].copy()\n",
    "                \n",
    "            tmp = output_errors * out_vector * (1.0 - out_vector)  \n",
    "            \n",
    "            #print(\"grad sig:\",tmp)\n",
    "            tmp = np.dot(tmp, in_vector.T)  \n",
    "            #print(\"layer_index:\", layer_index,\"grads:\", tmp)\n",
    "            #print (\"weight before \",self.weights_matrices[layer_index-1])\n",
    "            self.weights_matrices[layer_index-1] += self.learning_rate * tmp\n",
    "            #print (\"weight after \", self.weights_matrices[layer_index-1])\n",
    "            output_errors = np.dot(self.weights_matrices[layer_index-1].T, \n",
    "                                   output_errors)\n",
    "            if self.bias:\n",
    "                output_errors = output_errors[:-1,:]\n",
    "            layer_index -= 1\n",
    "            \n",
    "\n",
    "       \n",
    "\n",
    "    def train(self, data_array, \n",
    "              target_array,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        intermediate_weights = []\n",
    "        for epoch in range(epochs):  \n",
    "            for i in range(len(data_array)):\n",
    "                self.train_single(data_array[i], target_array[i])\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.wih.copy(), \n",
    "                                             self.who.copy()))\n",
    "            e, e_p = self.evaluate(data_array, target_array)\n",
    "            print(\"epoch:\", epoch, \"MSE train: \", e)\n",
    "            \n",
    "        return intermediate_weights      \n",
    "        \n",
    "\n",
    "               \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "\n",
    "        no_of_layers = len(self.structure)\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            print (input_vector.shape)\n",
    "            input_vector = np.concatenate( (input_vector, np.ones((input_vector.shape[0],1))),axis=1 )\n",
    "        in_vector = np.array(input_vector, ndmin=2).T\n",
    "\n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        while layer_index < no_of_layers:\n",
    "            x = np.dot(self.weights_matrices[layer_index-1], \n",
    "                       in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            \n",
    "            # input vector for next layer\n",
    "            in_vector = out_vector\n",
    "            if self.bias: \n",
    "                \n",
    "                in_vector = np.concatenate( (in_vector, \n",
    "                                             np.ones((in_vector.shape[0],1)) ),axis=1)            \n",
    "            \n",
    "            layer_index += 1\n",
    "  \n",
    "    \n",
    "        return out_vector\n",
    "    \n",
    "    def evaluate(self, data, y_real):\n",
    "        y_pred = (self.run(data)).T\n",
    "        e=np.mean(np.multiply(y_real-y_pred, y_real-y_pred))\n",
    "        e_prime= 2*(y_pred-y_real)/y_real.size\n",
    "        return e, y_pred\n",
    "    \n",
    "    def save_paras(self):\n",
    "        return self.weights_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2a861baa43c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bc44e23e7f3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, target_array, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 intermediate_weights.append((self.wih.copy(), \n\u001b[1;32m    125\u001b[0m                                              self.who.copy()))\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MSE train: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bc44e23e7f3a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data, y_real)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0me_prime\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bc44e23e7f3a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, input_vector)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# adding bias node to the end of the inpuy_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0min_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "ANN = NeuralNetwork(network_structure=[input_size, 30,30, output_size],\n",
    "                               learning_rate=0.1,\n",
    "                               bias=True)\n",
    "    \n",
    "    \n",
    "ANN.train(train_X, train_Y, epochs=epochs)\n",
    "e, y_pred = ANN.evaluate(train_X, train_Y)\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    print(\"value compare\", y_pred[i], train_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf1 = open(\"model1.txt\",\"w\")\\nf2 = open(\"model2.txt\",\"w\")\\nf3 = open(\"model3.txt\",\"w\")\\n\\nfor ele1 in model[0]:\\n    f1.write(str(ele1))\\n    f1.write(\"\\n\")    \\n\\nfor ele2 in model[1]:\\n    f2.write(str(ele2))\\n    f2.write(\"\\n\")    \\n\\nfor ele3 in model[2]:\\n    f3.write(str(ele3))\\n    f3.write(\"\\n\")    \\n\\n'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  ANN.save_paras()\n",
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSE: test', 0.0026102726192486214)\n",
      "('value compare', array([0.93470341, 0.90058947]), array([0.96843353, 0.99098544]))\n",
      "('value compare', array([0.93890318, 0.40404014]), array([0.96842038, 0.40097286]))\n",
      "('value compare', array([0.02911926, 0.37896586]), array([0.00098698, 0.4009778 ]))\n",
      "('value compare', array([0.02895701, 0.40119128]), array([0.01299468, 0.41285616]))\n",
      "('value compare', array([0.93679751, 0.77081933]), array([0.85638241, 0.69698821]))\n",
      "('value compare', array([0.87429444, 0.35243553]), array([0.85524828, 0.30877516]))\n",
      "('value compare', array([0.06366623, 0.77788793]), array([0.14350901, 0.72088336]))\n",
      "('value compare', array([0.05638944, 0.78154496]), array([0.14803633, 0.71922215]))\n",
      "('value compare', array([0.87429444, 0.35243553]), array([0.84182302, 0.30882461]))\n",
      "('value compare', array([0.08717266, 0.35021697]), array([0.14358403, 0.3996886 ]))\n",
      "('value compare', array([0.09227292, 0.87283564]), array([0.15489069, 0.79887156]))\n",
      "('value compare', array([0.17173058, 0.26839412]), array([0.16374998, 0.30874106]))\n",
      "('value compare', array([0.87727972, 0.35313251]), array([0.84971258, 0.31433446]))\n",
      "('value compare', array([0.87511021, 0.35374739]), array([0.83735673, 0.31159384]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "e, y_pred = ANN.evaluate(test_X, test_Y)\n",
    "print(\"MSE: test\", e)\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    print(\"value compare\", y_pred[i], test_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
